ğŸ“„ PDF RAG System (Multi-Format Document Intelligence)

A full-stack Retrieval-Augmented Generation (RAG) system that allows users to upload documents (PDF, Word, PowerPoint) and ask intelligent questions based on their content.

Built using FastAPI, LangChain, ChromaDB, Gemini/Ollama, and React.

ğŸ¯ Why This Project?

Modern applications require intelligent document understanding.

This project demonstrates:

How to build a complete RAG pipeline

How to process multiple document formats

How to store semantic embeddings in a vector database

How to retrieve relevant context for LLMs

How to build a full backend + frontend system

How to structure a production-ready project

This is not just a demo â€” it is a complete document Q&A system.

ğŸ§  How It Works (Architecture Flow)
User
  â”‚
  â–¼
React Frontend (Upload / Chat UI)
  â”‚
  â–¼
FastAPI Backend
  â”‚
  â”œâ”€â”€ File Router
  â”‚      â”œâ”€â”€ PDF Loader
  â”‚      â”œâ”€â”€ DOCX Loader
  â”‚      â””â”€â”€ PPT Extractor
  â”‚
  â–¼
Text Splitter
  â”‚
  â–¼
Embedding Generator (Gemini / Ollama)
  â”‚
  â–¼
ChromaDB (Vector Store)
  â”‚
  â–¼
Retriever
  â”‚
  â–¼
LLM (Gemini / Ollama)
  â”‚
  â–¼
Final Answer Returned to User

ğŸ— Project Architecture
pdf-rag-gemini/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/       # File handling & utilities
â”‚   â”‚   â”œâ”€â”€ rag/        # RAG pipeline logic
â”‚   â”‚   â”œâ”€â”€ llm/        # LLM integrations
â”‚   â”‚   â””â”€â”€ main.py     # FastAPI entry point
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ public/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/        # Uploaded files
â”‚   â””â”€â”€ chroma_db/      # Vector DB (auto-generated)
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

ğŸš€ Features
Backend

Multi-format support (PDF, DOCX, PPT)

Automatic file type detection

Background processing

Status tracking

Vector database persistence (ChromaDB)

REST API endpoints

Document list & delete endpoints

Gemini and Ollama support

Frontend

Drag-and-drop upload

Upload progress tracking

Document library view

File-type icons

Delete document button

Chat interface


âš™ï¸ Complete Setup Guide (Actual Working Version)

1ï¸âƒ£ Clone Repository
git clone https://github.com/IshaRoyxR/pdf-rag-gemini.git
cd pdf-rag-gemini

ğŸ§  Step 2: Install and Run Ollama (Required)

Download Ollama from:

https://ollama.com/download

After installation, pull the model:

ollama pull llama3       #Run


Start Ollama (if not auto-running):

ollama serve              #Run

ğŸ” Step 2: Create Environment File (Required)

Before starting Docker, create a .env file in the project root.

You can copy the example file:

copy .env.example .env


(Windows)

Or:

cp .env.example .env


(Mac/Linux)

Then edit .env if needed.

ğŸ³ Step 4: Start Backend (Docker)

Stop previous containers:

docker compose down                                      #Run


Build backend:

docker compose build backend                            #Run


Start backend:

docker compose up                                       #Run


Backend runs at:

http://localhost:8000


Check API docs:

http://localhost:8000/docs

ğŸ¨ Step 5: Start Frontend

Open new terminal:

cd frontend                  
npm install
npm start


Frontend runs at:

http://localhost:3000

ğŸ§  System Architecture (Your Real Setup)
User
   â†“
React Frontend (localhost:3000)
   â†“
FastAPI Backend (Docker container)
   â†“
Ollama (Local Model Server)
   â†“
ChromaDB (Vector Store)
   â†“
Response to User