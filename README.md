ğŸ“„ PDF RAG System (Multi-Format Document Intelligence)

A full-stack Retrieval-Augmented Generation (RAG) system that allows users to upload documents (PDF, Word, PowerPoint) and ask intelligent questions based on their content.

Built using FastAPI, LangChain, ChromaDB, Gemini/Ollama, and React.

ğŸ¯ Why This Project?

Modern applications require intelligent document understanding.

This project demonstrates:

How to build a complete RAG pipeline

How to process multiple document formats

How to store semantic embeddings in a vector database

How to retrieve relevant context for LLMs

How to build a full backend + frontend system

How to structure a production-ready project

This is not just a demo â€” it is a complete document Q&A system.

ğŸ§  How It Works (Architecture Flow)
User
  â”‚
  â–¼
React Frontend (Upload / Chat UI)
  â”‚
  â–¼
FastAPI Backend
  â”‚
  â”œâ”€â”€ File Router
  â”‚      â”œâ”€â”€ PDF Loader
  â”‚      â”œâ”€â”€ DOCX Loader
  â”‚      â””â”€â”€ PPT Extractor
  â”‚
  â–¼
Text Splitter
  â”‚
  â–¼
Embedding Generator (Gemini / Ollama)
  â”‚
  â–¼
ChromaDB (Vector Store)
  â”‚
  â–¼
Retriever
  â”‚
  â–¼
LLM (Gemini / Ollama)
  â”‚
  â–¼
Final Answer Returned to User

ğŸ— Project Architecture
pdf-rag-gemini/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/        # API endpoints
â”‚   â”‚   â”œâ”€â”€ core/       # File handling & utilities
â”‚   â”‚   â”œâ”€â”€ rag/        # RAG pipeline logic
â”‚   â”‚   â”œâ”€â”€ llm/        # LLM integrations
â”‚   â”‚   â””â”€â”€ main.py     # FastAPI entry point
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â””â”€â”€ public/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/        # Uploaded files
â”‚   â””â”€â”€ chroma_db/      # Vector DB (auto-generated)
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â””â”€â”€ README.md

ğŸš€ Features
Backend

Multi-format support (PDF, DOCX, PPT)

Automatic file type detection

Background processing

Status tracking

Vector database persistence (ChromaDB)

REST API endpoints

Document list & delete endpoints

Gemini and Ollama support

Frontend

Drag-and-drop upload

Upload progress tracking

Document library view

File-type icons

Delete document button

Chat interface


âš™ï¸ Complete Setup Guide (Backend + Frontend)
1ï¸âƒ£ Clone Repository
git clone https://github.com/IshaRoyxR/pdf-rag-gemini.git
cd pdf-rag-gemini

ğŸ–¥ Backend Setup

Step 1: Create Virtual Environment
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # Mac/Linux

Step 2: Install Dependencies
pip install -r backend/requirements.txt

Step 3: Create Environment File
Create a .env file in the root directory:
GOOGLE_API_KEY=your_google_api_key
MODEL_NAME=gemini-pro

Step 4: Run Backend Server
uvicorn backend.app.main:app --reload


Backend will run at:
http://127.0.0.1:8000


You can check:
http://127.0.0.1:8000/docs


for Swagger API documentation.

ğŸ¨ Frontend Setup

Open a new terminal:
cd frontend
npm install
npm start


Frontend runs at:

http://localhost:3000


Make sure backend is running before starting frontend.

ğŸ³ Docker Setup (Optional)

To run full application using Docker:
docker-compose up --build